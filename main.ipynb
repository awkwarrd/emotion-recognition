{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Emotions Recognition\n",
    "\n",
    "Project is in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils.image_utils import load_img, img_to_array\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir(\"images/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\images\\train\\angry\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\images\\train\\angry\\1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\images\\train\\angry\\10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\images\\train\\angry\\10002.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\images\\train\\angry\\10016.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image  emotion\n",
       "0      images\\images\\train\\angry\\0.jpg        0\n",
       "1      images\\images\\train\\angry\\1.jpg        0\n",
       "2     images\\images\\train\\angry\\10.jpg        0\n",
       "3  images\\images\\train\\angry\\10002.jpg        0\n",
       "4  images\\images\\train\\angry\\10016.jpg        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_map = {\"angry\" : 0, \"disgust\" : 1, \"fear\" : 2, \"happy\": 3, \"neutral\": 4, \"sad\" : 5, \"surprise\" : 6}\n",
    "\n",
    "train_data = {\"image\" : [], \"emotion\" : []}\n",
    "\n",
    "\n",
    "for emotion in listdir(\"images\\\\images\\\\train\"):\n",
    "    emotion_type = emotion_map[emotion]\n",
    "    emotion_dir = \"images\\\\images\\\\train\\\\\" + emotion + \"\\\\\"\n",
    "    for image_name in listdir(emotion_dir):\n",
    "        image_path = emotion_dir + image_name\n",
    "        train_data[\"image\"].append(image_path)\n",
    "        train_data[\"emotion\"].append(emotion_type)\n",
    "        \n",
    "        \n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "train_df.to_csv(\"train_df.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\images\\validation\\angry\\10052.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\images\\validation\\angry\\10065.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\images\\validation\\angry\\10079.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\images\\validation\\angry\\10095.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\images\\validation\\angry\\10121.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image  emotion\n",
       "0  images\\images\\validation\\angry\\10052.jpg        0\n",
       "1  images\\images\\validation\\angry\\10065.jpg        0\n",
       "2  images\\images\\validation\\angry\\10079.jpg        0\n",
       "3  images\\images\\validation\\angry\\10095.jpg        0\n",
       "4  images\\images\\validation\\angry\\10121.jpg        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = {\"image\" : [], \"emotion\" : []}\n",
    "\n",
    "\n",
    "for emotion in listdir(\"images\\\\images\\\\validation\"):\n",
    "    emotion_type = emotion_map[emotion]\n",
    "    emotion_dir = \"images\\\\images\\\\validation\\\\\" + emotion + \"\\\\\"\n",
    "    for image_name in listdir(emotion_dir):\n",
    "        image_path = emotion_dir + image_name\n",
    "        test_data[\"image\"].append(image_path)\n",
    "        test_data[\"emotion\"].append(emotion_type)\n",
    "        \n",
    "        \n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "test_df.to_csv(\"test_df.csv\")\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"test_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3    7164\n",
       "4    4982\n",
       "5    4938\n",
       "2    4103\n",
       "0    3993\n",
       "6    3205\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3    1825\n",
       "4    1216\n",
       "5    1139\n",
       "2    1018\n",
       "0     960\n",
       "6     797\n",
       "1     111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3    7164\n",
       "4    4982\n",
       "5    4938\n",
       "2    4103\n",
       "0    3993\n",
       "6    3205\n",
       "1     436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"emotion\"].value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[[72.0, 72.0, 72.0], [78.0, 78.0, 78.0], [81....\n",
       "1        [[[152.0, 152.0, 152.0], [149.0, 149.0, 149.0]...\n",
       "2        [[[29.0, 29.0, 29.0], [25.0, 25.0, 25.0], [21....\n",
       "3        [[[32.0, 32.0, 32.0], [23.0, 23.0, 23.0], [20....\n",
       "4        [[[222.0, 222.0, 222.0], [218.0, 218.0, 218.0]...\n",
       "                               ...                        \n",
       "28816    [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...\n",
       "28817    [[[130.0, 130.0, 130.0], [134.0, 134.0, 134.0]...\n",
       "28818    [[[243.0, 243.0, 243.0], [220.0, 220.0, 220.0]...\n",
       "28819    [[[253.0, 253.0, 253.0], [252.0, 252.0, 252.0]...\n",
       "28820    [[[213.0, 213.0, 213.0], [218.0, 218.0, 218.0]...\n",
       "Name: image_array, Length: 28821, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"image_array\"] = train_df[\"image\"].apply(lambda x : img_to_array(load_img(x)))\n",
    "train_df[\"image_array\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[[58.0, 58.0, 58.0], [66.0, 66.0, 66.0], [70....\n",
       "1       [[[23.0, 23.0, 23.0], [26.0, 26.0, 26.0], [21....\n",
       "2       [[[201.0, 201.0, 201.0], [182.0, 182.0, 182.0]...\n",
       "3       [[[93.0, 93.0, 93.0], [86.0, 86.0, 86.0], [78....\n",
       "4       [[[11.0, 11.0, 11.0], [6.0, 6.0, 6.0], [1.0, 1...\n",
       "                              ...                        \n",
       "7061    [[[255.0, 255.0, 255.0], [253.0, 253.0, 253.0]...\n",
       "7062    [[[84.0, 84.0, 84.0], [71.0, 71.0, 71.0], [70....\n",
       "7063    [[[250.0, 250.0, 250.0], [253.0, 253.0, 253.0]...\n",
       "7064    [[[228.0, 228.0, 228.0], [224.0, 224.0, 224.0]...\n",
       "7065    [[[78.0, 78.0, 78.0], [116.0, 116.0, 116.0], [...\n",
       "Name: image_array, Length: 7066, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"image_array\"] = test_df[\"image\"].apply(lambda x : img_to_array(load_img(x)))\n",
    "test_df[\"image_array\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I've decided to use image augumentation in order to solve 2 problems:\n",
    "1. Small amount of train data\n",
    "2. Class disbalance\n",
    "\n",
    "To solve class disbalance, we need to check class balance in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3    0.248569\n",
       "4    0.172860\n",
       "5    0.171333\n",
       "2    0.142361\n",
       "0    0.138545\n",
       "6    0.111204\n",
       "1    0.015128\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"emotion\"].value_counts() / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to augment the training dataset so that I have 10000 images of each emotion. Before applying image augmentation, I need to know how many times I need to apply it to solve the class imbalance problem. So, let's calculate this. I will round the calculated value so that they are natural numbers, and after applying it, I will remove some extra examples to have the same number of exemplars of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "3     2\n",
       "4     3\n",
       "5     3\n",
       "2     3\n",
       "0     3\n",
       "6     4\n",
       "1    23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "(10000 / train_df[\"emotion\"].value_counts()).apply(lambda x : ceil(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"emotion\"] = train_df[\"emotion\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "augumentaion_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "def augumentation(image, generator):\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image_augumented = generator.flow(image).next()[0]\n",
    "    return image_augumented\n",
    "\n",
    "\n",
    "class_ratios = (20000 / train_df[\"emotion\"].value_counts()).apply(lambda x : ceil(x))\n",
    "\n",
    "emotion_map = dict()\n",
    "\n",
    "for emotion in range(0, 7):\n",
    "    emotion_map[emotion] = train_df[train_df[\"emotion\"] == emotion]\n",
    "\n",
    "\n",
    "augumented_emotion_map = dict()\n",
    "\n",
    "for emotion in range(0, 7):\n",
    "    augumented_images = pd.DataFrame()\n",
    "    for _ in range(class_ratios[emotion]):\n",
    "        temp = emotion_map[emotion].copy()\n",
    "        temp[\"image_array\"] = temp[\"image_array\"].apply(lambda x : augumentation(x, augumentaion_generator))\n",
    "        augumented_images = pd.concat([augumented_images, temp], axis=\"rows\")\n",
    "    \n",
    "    augumented_emotion_map[emotion] = augumented_images\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "0    20000\n",
       "1    20000\n",
       "2    20000\n",
       "3    20000\n",
       "4    20000\n",
       "5    20000\n",
       "6    20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augumented_train = pd.DataFrame()\n",
    "\n",
    "for emotion in range(0, 7):\n",
    "    augumented_train = pd.concat([augumented_train, augumented_emotion_map[emotion].sample(20000)], axis=\"rows\")\n",
    "    \n",
    "augumented_train[\"emotion\"].value_counts()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 47, 47, 64)        832       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 47, 47, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 23, 23, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 128)       32896     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 11, 11, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 9, 9, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 2, 2, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,302,407\n",
      "Trainable params: 2,300,487\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, Input, Conv2D, MaxPool2D, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.resnet import ResNet101\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Input \n",
    "model.add(Input(shape=(48, 48, 3)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=Adam(0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4375/4375 [==============================] - 102s 22ms/step - loss: 1.7601 - accuracy: 0.3004 - val_loss: 1.6216 - val_accuracy: 0.4007 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "4375/4375 [==============================] - 88s 20ms/step - loss: 1.4703 - accuracy: 0.4392 - val_loss: 1.4475 - val_accuracy: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "4375/4375 [==============================] - 82s 19ms/step - loss: 1.3380 - accuracy: 0.4943 - val_loss: 1.1836 - val_accuracy: 0.5444 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 1.2536 - accuracy: 0.5251 - val_loss: 1.2185 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 1.1896 - accuracy: 0.5522 - val_loss: 1.1213 - val_accuracy: 0.5767 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 1.1351 - accuracy: 0.5719 - val_loss: 1.1226 - val_accuracy: 0.5740 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "4375/4375 [==============================] - 88s 20ms/step - loss: 1.0908 - accuracy: 0.5859 - val_loss: 1.0961 - val_accuracy: 0.5873 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 1.0552 - accuracy: 0.6025 - val_loss: 1.1132 - val_accuracy: 0.5826 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 1.0203 - accuracy: 0.6139 - val_loss: 1.0958 - val_accuracy: 0.5933 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "4375/4375 [==============================] - 82s 19ms/step - loss: 0.9926 - accuracy: 0.6239 - val_loss: 1.1252 - val_accuracy: 0.5736 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 0.9633 - accuracy: 0.6349 - val_loss: 1.0714 - val_accuracy: 0.6050 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 0.9378 - accuracy: 0.6452 - val_loss: 1.0278 - val_accuracy: 0.6257 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 0.9131 - accuracy: 0.6547 - val_loss: 1.0143 - val_accuracy: 0.6302 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "4375/4375 [==============================] - 87s 20ms/step - loss: 0.8929 - accuracy: 0.6620 - val_loss: 1.0408 - val_accuracy: 0.6144 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 0.8735 - accuracy: 0.6698 - val_loss: 1.0658 - val_accuracy: 0.6160 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "4375/4375 [==============================] - 86s 20ms/step - loss: 0.8499 - accuracy: 0.6769 - val_loss: 1.0587 - val_accuracy: 0.6077 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "4375/4375 [==============================] - 89s 20ms/step - loss: 0.8303 - accuracy: 0.6857 - val_loss: 1.0785 - val_accuracy: 0.6169 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "4375/4375 [==============================] - 85s 19ms/step - loss: 0.8129 - accuracy: 0.6915 - val_loss: 1.0324 - val_accuracy: 0.6336 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "4375/4375 [==============================] - 83s 19ms/step - loss: 0.7638 - accuracy: 0.7098 - val_loss: 1.0145 - val_accuracy: 0.6377 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "4375/4375 [==============================] - 88s 20ms/step - loss: 0.7509 - accuracy: 0.7145 - val_loss: 1.0227 - val_accuracy: 0.6374 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 0.7420 - accuracy: 0.7205 - val_loss: 1.0145 - val_accuracy: 0.6386 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "4375/4375 [==============================] - 84s 19ms/step - loss: 0.7362 - accuracy: 0.7211 - val_loss: 1.0151 - val_accuracy: 0.6417 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "4375/4375 [==============================] - 85s 19ms/step - loss: 0.7348 - accuracy: 0.7227 - val_loss: 1.0232 - val_accuracy: 0.6370 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23903263610>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1/255.)\n",
    "test_generator = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_images = np.stack(augumented_train[\"image_array\"].values)\n",
    "train_labels = augumented_train[\"emotion\"].values\n",
    "\n",
    "test_images = np.stack(test_df[\"image_array\"].values)\n",
    "test_labels = test_df[\"emotion\"].values\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=7)\n",
    "test_labels = to_categorical(test_labels, num_classes=7)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(patience=5, factor=0.1)\n",
    "\n",
    "hitsory = model.fit(train_generator.flow(train_images, train_labels, batch_size=32),\n",
    "          validation_data=test_generator.flow(test_images, test_labels, batch_size=32),\n",
    "          epochs=100, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "temp = pd.DataFrame(hitsory.history).reset_index()\n",
    "\n",
    "plt.plot(temp[\"index\"], temp[\"loss\"])\n",
    "plt.plot(temp[\"index\"], temp[\"val_loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"model0_64va.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging with OpenCV and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model import and prediction parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model, load_model\n",
    "import numpy as np\n",
    "\n",
    "model = load_model(\"model0_64va.h5\")\n",
    "\n",
    "def parce_predictions(x : np.array):\n",
    "    emotion_map_reversed = {0 : \"angry\", 1 : \"disgust\" , 2 : \"fear\" , 3 : \"happy\", 4 : \"neutral\", 5 : \"sad\" , 6 : \"surprise\"}\n",
    "    emotion = x.argmax()\n",
    "    return emotion_map_reversed[emotion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Defininitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from keras.utils.image_utils import array_to_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "temp = None\n",
    "crop = None\n",
    "\n",
    "window_name = 'Image'\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "org = (50, 50) \n",
    "fontScale = 1\n",
    "color = (255, 0, 0) \n",
    "thickness = 2\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    text = None\n",
    " \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        crop = (x, w, y, h)\n",
    "        face_image = gray[y:y+h, x:x+w]\n",
    "\n",
    "        face_image = face_image[..., np.newaxis]\n",
    "\n",
    "        image = img_to_array(array_to_img(face_image).resize((48, 48)))\n",
    "        image = np.repeat(image, 3, axis=2)\n",
    "\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\t\n",
    "        text = parce_predictions(model.predict(image, verbose=0))\n",
    "    \n",
    "    frame = cv2.putText(frame, text, org, font,  \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "    cv2.imshow('Video', frame)\n",
    "    temp = frame\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that version of project I've achieved 64 validation accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
